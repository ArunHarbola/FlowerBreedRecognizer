{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "data_dir='./data/flowers'\n",
    "\n",
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    for category in categories:\n",
    "      path = os.path.join(data_dir, category)\n",
    "      print(path)\n",
    "      label = categories.index(category)\n",
    "\n",
    "      for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        try :\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "          image = cv2.resize(image, (224, 224))\n",
    "\n",
    "          image = np.array(image, dtype=np.float32)\n",
    "\n",
    "          data.append([image,label])\n",
    "\n",
    "        except Exception as e:\n",
    "          pass\n",
    "    \n",
    "    print(len(data))   \n",
    "\n",
    "    pik = open('data.pickle', 'wb')\n",
    "    pickle.dump(data,pik)\n",
    "    pik.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/flowers\\daisy\n",
      "./data/flowers\\dandelion\n",
      "./data/flowers\\rose\n",
      "./data/flowers\\sunflower\n",
      "./data/flowers\\tulip\n",
      "4317\n"
     ]
    }
   ],
   "source": [
    "make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  pick = open('data.pickle','rb')\n",
    "  data = pickle.load(pick)\n",
    "  pick.close()\n",
    "\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  feature = []\n",
    "  labels = []\n",
    "\n",
    "  for img, label in data:\n",
    "    feature.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "  feature = np.array(feature, dtype=np.float32)\n",
    "  labels=np.array(labels)\n",
    "\n",
    "  feature = feature/255.0\n",
    "\n",
    "  return [feature, labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "(feature, labels) = load_data()\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(feature,labels, test_size = 0.1)\n",
    "\n",
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input([224,224,3])\n",
    "\n",
    "\n",
    "conv1=tf.keras.layers.Conv2D(filters = 32, kernel_size=(5,5), padding='Same',\n",
    "                             activation = 'relu')(input_layer)\n",
    "\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "                             \n",
    "\n",
    "\n",
    "conv2=tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool1)\n",
    "\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv2)\n",
    "\n",
    "\n",
    "\n",
    "conv3=tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool2)\n",
    "\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv3)\n",
    "\n",
    "\n",
    "\n",
    "conv4=tf.keras.layers.Conv2D(filters = 96, kernel_size=(3,3), padding='Same',\n",
    "                             activation = 'relu')(pool3)\n",
    "\n",
    "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv3)\n",
    "\n",
    "\n",
    "flt1 = tf.keras.layers.Flatten()(pool4)\n",
    "\n",
    "dn1 = tf.keras.layers.Dense(512,activation='relu')(flt1)\n",
    "out = tf.keras.layers.Dense(5, activation='softmax')(dn1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 113s 3s/step - loss: 0.6684 - accuracy: 0.7511\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 111s 3s/step - loss: 0.4352 - accuracy: 0.8450\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 112s 3s/step - loss: 0.2937 - accuracy: 0.9037\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 111s 3s/step - loss: 0.2158 - accuracy: 0.9277\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 112s 3s/step - loss: 0.1185 - accuracy: 0.9637\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 111s 3s/step - loss: 0.0843 - accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 111s 3s/step - loss: 0.0550 - accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 111s 3s/step - loss: 0.0366 - accuracy: 0.9918\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 110s 3s/step - loss: 0.0228 - accuracy: 0.9951\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 109s 3s/step - loss: 0.0328 - accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a73f4a2e90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(input_layer, out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 100, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea7664663f5402f25200e248ec25c4127168595a283a511cd371d5aae568de60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
